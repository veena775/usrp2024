/var/spool/slurmd/job2264422/slurm_script: line 13: conda: command not found
[I 2024-10-24 02:27:06,464] A new study created in RDB with name: MPk_nwLH_params_200
[W 2024-10-24 02:27:06,776] Trial 0 failed with parameters: {'lr': 0.0005554451768496995, 'wd': 2.6675403638755506e-07, 'h1': 19, 'dr': 0.1960287907786768} because of the following error: RuntimeError('Error(s) in loading state_dict for model_1hl:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([26, 79]) from checkpoint, the shape in current model is torch.Size([19, 79]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([19]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([7, 26]) from checkpoint, the shape in current model is torch.Size([7, 19]).').
Traceback (most recent call last):
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/vk9342/USRP2024/pytorch/main_continue.py", line 42, in __call__
    model.load_state_dict(torch.load(fmodel))
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for model_1hl:
	size mismatch for fc1.weight: copying a param with shape torch.Size([26, 79]) from checkpoint, the shape in current model is torch.Size([19, 79]).
	size mismatch for fc1.bias: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([19]).
	size mismatch for fc2.weight: copying a param with shape torch.Size([7, 26]) from checkpoint, the shape in current model is torch.Size([7, 19]).
[W 2024-10-24 02:27:06,778] Trial 0 failed with value None.
CUDA Available
Traceback (most recent call last):
  File "/home/vk9342/USRP2024/pytorch/main_continue.py", line 137, in <module>
    study.optimize(objective, n_trials, n_jobs=n_jobs)
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/vk9342/USRP2024/pytorch/main_continue.py", line 42, in __call__
    model.load_state_dict(torch.load(fmodel))
  File "/home/vk9342/.conda/envs/usrp/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2189, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for model_1hl:
	size mismatch for fc1.weight: copying a param with shape torch.Size([26, 79]) from checkpoint, the shape in current model is torch.Size([19, 79]).
	size mismatch for fc1.bias: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([19]).
	size mismatch for fc2.weight: copying a param with shape torch.Size([7, 26]) from checkpoint, the shape in current model is torch.Size([7, 19]).
